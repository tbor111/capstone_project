{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm.session import sessionmaker\n",
    "from bs4 import BeautifulSoup\n",
    "import cookielib\n",
    "import urllib2\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    #request = urllib2.Request(url)\n",
    "    #response = urllib2.urlopen(url) #request\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html.decode('utf-8', 'ignore'), 'html.parser')\n",
    "    results = soup.find_all('div', attrs = {'class': 'story-body'})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_soup(results):\n",
    "\n",
    "    # initialize lists\n",
    "    titles = []\n",
    "    dates = []\n",
    "    links = []\n",
    "    full_texts = []\n",
    "    authors = []\n",
    "    sections = []\n",
    "\n",
    "    # scrape results into lists\n",
    "    for x in results:\n",
    "        # get link\n",
    "        link = x.find('a')['href']\n",
    "        # set regex to eliminate interactive features\n",
    "        match = re.search('^http://www.nytimes.com/20', link)\n",
    "        if match:\n",
    "            links.append(link)\n",
    "\n",
    "    # resoup it\n",
    "    for link in links:\n",
    "        all_p = ''\n",
    "        cj = cookielib.CookieJar()\n",
    "        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))\n",
    "        new_soup = BeautifulSoup(opener.open(link).read().decode('utf-8', 'ignore'), 'html.parser')\n",
    "        # get the article content\n",
    "        body = new_soup.find_all('p', attrs = {'class': 'story-body-text story-content'})\n",
    "        for p in body:\n",
    "            new_p = p.text.strip()\n",
    "            all_p = all_p + new_p\n",
    "        full_texts.append(all_p)\n",
    "\n",
    "        # get titles\n",
    "        title = new_soup.find('meta', attrs = {'property': 'og:title'})['content']\n",
    "        titles.append(title)\n",
    "\n",
    "        # get authors\n",
    "        author = new_soup.find('meta', attrs = {'name': 'author'})['content']\n",
    "        authors.append(author)\n",
    "\n",
    "        # get sections\n",
    "        section = new_soup.find('meta', attrs = {'name': 'CG'})['content']\n",
    "        sections.append(section)\n",
    "\n",
    "        # get dates\n",
    "        date = new_soup.find('meta', attrs = {'name': 'pdate'})['content']\n",
    "        dates.append(date)\n",
    "\n",
    "    data_dict = {\n",
    "        'title': titles, 'link': links, 'author': authors, 'body': full_texts,\n",
    "        'section': sections, 'date': dates\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(data_dict):\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = get_soup('http://www.nytimes.com/section/fashion')\n",
    "data_dict = scrape_soup(results)\n",
    "df = make_df(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>section</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>The Screen Actors Guild Awards took place at t...</td>\n",
       "      <td>20170129</td>\n",
       "      <td>http://www.nytimes.com/2017/01/29/fashion/scre...</td>\n",
       "      <td>fashion</td>\n",
       "      <td>Screen Actors Guild Awards Red Carpet Fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               body      date  \\\n",
       "0         The Screen Actors Guild Awards took place at t...  20170129   \n",
       "\n",
       "                                                link  section  \\\n",
       "0  http://www.nytimes.com/2017/01/29/fashion/scre...  fashion   \n",
       "\n",
       "                                           title  \n",
       "0  Screen Actors Guild Awards Red Carpet Fashion  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://teresaborcuch@localhost:5433/capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear staging\n",
    "clear_staging_query = 'DELETE FROM nyt_staging *;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sqlalchemy session and clear staging\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "engine.execute(clear_staging_query)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add dataframe to staging\n",
    "df.to_sql('nyt_staging', engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_unique_query = '''\n",
    "INSERT INTO ny_times (title, date, author, body, link, section)\n",
    "SELECT title, date, author, body, link, section\n",
    "FROM nyt_staging\n",
    "WHERE NOT EXISTS (SELECT title, date, author, body, link, section\n",
    "FROM ny_times\n",
    "WHERE ny_times.title = nyt_staging.title);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the move_unique_query\n",
    "engine.execute(move_unique_query)\n",
    "session.commit()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete duplicates\n",
    "del_dup_query = '''\n",
    "DELETE FROM ny_times WHERE id NOT in \n",
    "(SELECT MIN(id) FORM ny_times GROUP BY title);\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
