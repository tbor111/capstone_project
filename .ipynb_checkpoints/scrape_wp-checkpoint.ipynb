{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from bs4 import BeautifulSoup\n",
    "import cookielib\n",
    "import urllib2\n",
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    #url = 'https://www.washingtonpost.com/politics'\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html.decode('utf-8', 'ignore'), 'html.parser')\n",
    "    results = soup.find_all('h3', attrs = {'class': ''})\n",
    "    print response.status_code\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dict(results):\n",
    "    # initialize lists\n",
    "    titles = []\n",
    "    dates = []\n",
    "    links = []\n",
    "    bodies = []\n",
    "    authors = []\n",
    "    sections = []\n",
    "\n",
    "    for x in results:\n",
    "        \n",
    "        link = x.find('a')['href']\n",
    "        match1 = re.search('^https://www.washingtonpost.com/video', link)\n",
    "        match2 = re.search('story.html', link)\n",
    "        if not match1 and match2:\n",
    "            links.append(link)\n",
    "\n",
    "    # resoup link\n",
    "    for link in links:\n",
    "        response = requests.get(link)\n",
    "        html = response.content\n",
    "        new_soup = BeautifulSoup(html.decode('utf-8', 'ignore'), 'html.parser')\n",
    "\n",
    "        # get title\n",
    "        title = new_soup.find('title').text.strip().replace(' - The Washington Post','')\n",
    "        titles.append(title)\n",
    "\n",
    "        # get body\n",
    "        all_p = ''\n",
    "        body = new_soup.find('article', itemprop = 'articleBody')\n",
    "        paragraphs = body.find_all('p')\n",
    "        for p in paragraphs:\n",
    "            new_p = p.text.strip().encode('ascii', 'ignore')\n",
    "            all_p = all_p + new_p   \n",
    "        bodies.append(all_p)\n",
    "\n",
    "        # get date\n",
    "        date = new_soup.find('span', attrs = {'itemprop': 'datePublished'})['content']\n",
    "        dates.append(date)\n",
    "\n",
    "        # get section\n",
    "        \n",
    "        scripts = new_soup.find_all('script')\n",
    "        pattern = 'var commercialNode'\n",
    "\n",
    "        for script in scripts:\n",
    "            #if (pattern.match(str(script.string))):\n",
    "            match = re.search(pattern, str(script))\n",
    "            if match:\n",
    "                text = script.text.strip()\n",
    "                text_list = text.split(';')\n",
    "                for x in text_list:\n",
    "                    match = re.search(pattern, x)\n",
    "                    if match:\n",
    "                        section = x.replace('var commercialNode=', '').replace('\"','')\n",
    "                        print section\n",
    "                        \n",
    "     \n",
    "        sections.append(section)\n",
    "        \n",
    "        # get author\n",
    "        author = ''\n",
    "        author_list = new_soup.find_all('span', attrs = {'itemprop': 'name'})\n",
    "        for a in author_list:\n",
    "            a = a.text.strip()\n",
    "            author = author + ',' + a\n",
    "        authors.append(author)\n",
    "        \n",
    "        data_dict = {\n",
    "            'title': titles, 'link': links, 'author': authors,\n",
    "            'body': bodies, 'section': sections, 'date': dates\n",
    "        }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_df(data_dict):\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n",
      "opinions\n"
     ]
    }
   ],
   "source": [
    "results = make_soup('http://www.washingtonpost.com/opinions')\n",
    "my_dict = make_dict(results)\n",
    "my_df = make_df(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>section</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,Ruth Marcus,Ruth Marcus</td>\n",
       "      <td>This is a column on a subject of broad public ...</td>\n",
       "      <td>2017-02-03T07:57-500</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/if-you...</td>\n",
       "      <td>opinions</td>\n",
       "      <td>If you’re reading this, Justice Kennedy, pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,George F. Will,George F. Will</td>\n",
       "      <td>Tight labor markets shrink income inequality b...</td>\n",
       "      <td>2017-02-03T07:57-500</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/want-t...</td>\n",
       "      <td>opinions</td>\n",
       "      <td>Want to reduce inequality? Try the Black Death.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,Kathleen Parker,Kathleen Parker</td>\n",
       "      <td>To review the lefts reaction to Supreme Court ...</td>\n",
       "      <td>2017-02-03T07:56-500</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/the-le...</td>\n",
       "      <td>opinions</td>\n",
       "      <td>The left’s boogeyman vision of Gorsuch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,Rachel Manteuffel,Rachel Manteuffel</td>\n",
       "      <td>Rachel Manteuffel works in The Posts Editorial...</td>\n",
       "      <td>2017-02-03T07:55-500</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/dear-r...</td>\n",
       "      <td>opinions</td>\n",
       "      <td>Dear Ruth Bader Ginsburg: If you need anything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,Henry Olsen,Henry Olsen</td>\n",
       "      <td>Henry Olsen is a senior fellow at the Ethics a...</td>\n",
       "      <td>2017-02-03T07:55-500</td>\n",
       "      <td>https://www.washingtonpost.com/opinions/trumps...</td>\n",
       "      <td>opinions</td>\n",
       "      <td>Trump’s election is the last, best hope to re-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 author  \\\n",
       "0              ,Ruth Marcus,Ruth Marcus   \n",
       "1        ,George F. Will,George F. Will   \n",
       "2      ,Kathleen Parker,Kathleen Parker   \n",
       "3  ,Rachel Manteuffel,Rachel Manteuffel   \n",
       "4              ,Henry Olsen,Henry Olsen   \n",
       "\n",
       "                                                body                  date  \\\n",
       "0  This is a column on a subject of broad public ...  2017-02-03T07:57-500   \n",
       "1  Tight labor markets shrink income inequality b...  2017-02-03T07:57-500   \n",
       "2  To review the lefts reaction to Supreme Court ...  2017-02-03T07:56-500   \n",
       "3  Rachel Manteuffel works in The Posts Editorial...  2017-02-03T07:55-500   \n",
       "4  Henry Olsen is a senior fellow at the Ethics a...  2017-02-03T07:55-500   \n",
       "\n",
       "                                                link   section  \\\n",
       "0  https://www.washingtonpost.com/opinions/if-you...  opinions   \n",
       "1  https://www.washingtonpost.com/opinions/want-t...  opinions   \n",
       "2  https://www.washingtonpost.com/opinions/the-le...  opinions   \n",
       "3  https://www.washingtonpost.com/opinions/dear-r...  opinions   \n",
       "4  https://www.washingtonpost.com/opinions/trumps...  opinions   \n",
       "\n",
       "                                               title  \n",
       "0  If you’re reading this, Justice Kennedy, pleas...  \n",
       "1    Want to reduce inequality? Try the Black Death.  \n",
       "2             The left’s boogeyman vision of Gorsuch  \n",
       "3  Dear Ruth Bader Ginsburg: If you need anything...  \n",
       "4  Trump’s election is the last, best hope to re-...  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = links[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "html = response.content\n",
    "new_soup = BeautifulSoup(html.decode('ascii', 'ignore'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "powerpost\n"
     ]
    }
   ],
   "source": [
    "scripts = new_soup.find_all('script')\n",
    "pattern = 'var commercialNode'\n",
    "\n",
    "for script in scripts:\n",
    "    #if (pattern.match(str(script.string))):\n",
    "    match = re.search(pattern, str(script))\n",
    "    if match:\n",
    "        text = script.text.strip()\n",
    "        text_list = text.split(';')\n",
    "        for x in text_list:\n",
    "            match = re.search(pattern, x)\n",
    "            if match:\n",
    "                section = x.replace('var commercialNode=', '').replace('\"','')\n",
    "                print section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scripts = new_soup.find_all('script')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scripts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
